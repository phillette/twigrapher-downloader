# -*- coding: utf-8 -*-
import requests
import json
import pprint
import pymysql
import time
import warnings
import datetime
import oauth2
import secretkeys

# GET from twitter API ---------------------------------------------------------

# use your own access keys for Twitter API
# user auth setting
CONSUMER_KEY = secretkeys.CONSUMER_KEY
CONSUMER_SECRET = secretkeys.CONSUMER_SECRET
ACCESS_TOKEN = secretkeys.ACCESS_TOKEN
ACCESS_TOKEN_SECRET = secretkeys.ACCESS_TOKEN_SECRET
USER_NAME = secretkeys.USER_NAME

def oauth_req(url, http_method="GET", post_body=b"", http_headers=None):
    consumer = oauth2.Consumer(key=CONSUMER_KEY, secret=CONSUMER_SECRET)
    token = oauth2.Token(key=ACCESS_TOKEN, secret=ACCESS_TOKEN_SECRET)
    client = oauth2.Client(consumer, token)
    resp, content = client.request( url, method=http_method, body=post_body, headers=http_headers )
    return content



# 900/15min limit
# calls max 17 times: twitter API statuses/user_timeline
def getAllNewTweetsByScreenName(screen_name, since = None):
    
    # return type: [{}] (list of tweets)

    alltweets = []

 
    url = 'https://api.twitter.com/1.1/statuses/user_timeline.json'
    if since is None:
        url += '?screen_name={}&count=200&tweet_mode=extended'.format(screen_name)
    else:
        url += '?screen_name={}&count=200&tweet_mode=extended&since_id={}'.format(screen_name, since)

    new_tweets = json.loads(oauth_req(url).decode('utf-8'))
    
    # print(json.dumps(json.loads(oauth_req(url).decode('utf-8')), indent=4, sort_keys=True, ensure_ascii=False))

    alltweets.extend(new_tweets)

    if 'error' in new_tweets:
        return None

    if len(new_tweets) != 0:
        oldest = int(alltweets[-1]['id_str']) - 1

    
        while len(new_tweets) > 0:

            url = 'https://api.twitter.com/1.1/statuses/user_timeline.json'
            if since is None:
                url += '?screen_name={}&count=200&tweet_mode=extended&max_id={}'.format(screen_name, oldest)
            else:
                url += '?screen_name={}&count=200&tweet_mode=extended&since_id={}&max_id={}'.format(screen_name, since, oldest)
            
            # print("getting tweets before %s" % oldest)
            
            try:
                new_tweets = json.loads(oauth_req(url).decode('utf-8'))
                if 'error' in new_tweets:
                    break
                alltweets.extend(new_tweets)

                oldest = int(alltweets[-1]['id_str']) - 1
            except:
                break

            
            # print("...%s tweets downloaded so far" % (len(alltweets)))

  
    # print(json.dumps(alltweets, indent=4, sort_keys=True, ensure_ascii=False))

    tweets = []
    for tw in alltweets:
        tweets.append(json.dumps(tw, ensure_ascii=False))

    return tweets

# 75/15min limit
# calls max 11 times: twitter API favorites/list
def getAllNewFavsByScreenName(screen_name, fav_count_diff):
    
    # return type: [{}] (list of tweets)

    if fav_count_diff > 2000:
        fav_count_diff = 2000

    if fav_count_diff == 0:
        return []

    remaining = fav_count_diff

    alltweets = []

    if fav_count_diff < 200:

        url = 'https://api.twitter.com/1.1/favorites/list.json'
        url += '?screen_name={}&count={}&tweet_mode=extended'.format(screen_name, str(fav_count_diff))
      
        new_tweets = json.loads(oauth_req(url).decode('utf-8'))

        if 'error' in new_tweets:
            return None

        alltweets.extend(new_tweets)
    else:
        
        url = 'https://api.twitter.com/1.1/favorites/list.json'
        url += '?screen_name={}&count=200&tweet_mode=extended'.format(screen_name)
      
        try:
            new_tweets = json.loads(oauth_req(url).decode('utf-8'))
            if 'error' in new_tweets:
                return None
            alltweets.extend(new_tweets)
        except:
            return None

        oldest = int(alltweets[-1]['id_str']) - 1

        remaining -= 200
    
        while remaining > 0:
            if remaining < 200:

                url = 'https://api.twitter.com/1.1/favorites/list.json'
                url += '?screen_name={}&count={}&tweet_mode=extended&max_id={}'.format(screen_name, str(fav_count_diff), oldest)
            else:
                
                url = 'https://api.twitter.com/1.1/favorites/list.json'
                url += '?screen_name={}&count=200&tweet_mode=extended&max_id={}'.format(screen_name, oldest)
                

            # print("getting tweets before %s" % oldest)
            try:
                new_tweets = json.loads(oauth_req(url).decode('utf-8'))
                if 'error' in new_tweets:
                    break
                alltweets.extend(new_tweets)
                oldest = int(alltweets[-1]['id_str']) - 1
            except:
                break
            
            
            # print("...%s tweets downloaded so far" % (len(alltweets)))

            remaining -= 200

  
    # print(json.dumps(alltweets, indent=4, sort_keys=True, ensure_ascii=False))

    tweets = []
    for tw in alltweets:
        tweets.append(json.dumps(tw, ensure_ascii=False))

    return tweets

# 15/15min limit
# calls max 1 time: twitter API followers/ids
def getAllNewFollowersByScreenName(screen_name):
    

    url = 'https://api.twitter.com/1.1/followers/ids.json'
    url += '?screen_name={}&count=5000'.format(screen_name)
      
    followersIDs = json.loads(oauth_req(url).decode('utf-8'))

    # print(json.dumps(followersIDs, indent=4, sort_keys=True, ensure_ascii=False))

    try:
        return followersIDs['ids']
    except:
        return None
    

# 15/15min limit
# calls max 1 time: twitter API friends/ids
def getAllNewFriendsByScreenName(screen_name):


    url = 'https://api.twitter.com/1.1/friends/ids.json'
    url += '?screen_name={}&count=5000'.format(screen_name)
    
    friendsIDs = json.loads(oauth_req(url).decode('utf-8'))

    # print(json.dumps(friendsIDs, indent=4, sort_keys=True, ensure_ascii=False))

    try:
        return friendsIDs['ids']
    except:
        return None

# 900/15min limit
# calls max 51 times: twitter API users/lookup
def convertToUserProfiles(ids):

    def chunks(l, n):
        for i in range(0, len(l), n):
            yield l[i:i + n]
    # pprint.pprint(list(chunks(ids, 100)))
    chunkedIds = list(chunks(ids, 100))

    profiles = []

    for i in range(len(chunkedIds)):

        cIDs = list(map(str,chunkedIds[i]))

        url = 'https://api.twitter.com/1.1/users/lookup.json'
        url += '?user_id={}&tweet_mode=extended'.format(str(",".join(cIDs)))
        
        profiles.extend(json.loads(oauth_req(url).decode('utf-8')))

    # print(json.dumps(profiles, indent=4, sort_keys=True, ensure_ascii=False))

    pros = []
    for pr in profiles:
        pros.append(json.dumps(pr, ensure_ascii=False))

    # pprint.pprint(pros)

    return pros


# 15/15min limit:
# calls max 1 time : twitter API lists/list: 
def getAllListsByScreenName(screen_name):
    
    url = 'https://api.twitter.com/1.1/lists/list.json'
    url += '?screen_name={}'.format(screen_name)

    lists = json.loads(oauth_req(url).decode('utf-8'))
   
    # for ls in lists:
    #    print(ls["id"])

    newList = []
    for ls in lists:
        newList.append(json.dumps(ls, ensure_ascii=False))
    
    try:
        return newList
    except:
        return None

# 900/15min limit:
# calls max 1 time : twitter API lists/members: 
def getListMembers(list_id):

    url = 'https://api.twitter.com/1.1/lists/members.json'
    url += '?list_id={}&skip_status=true&count=5000'.format(list_id)

    members = json.loads(oauth_req(url).decode('utf-8'))

    # print(members["users"])

    return members["users"]





# access my twigrapher DB ---------------------------------------------------------


def insertToDB(hostname, uname, dbname, theCharset, table, cols, vals):
    
    # args types:
    #     hostname: str
    #     uname: str
    #     dbname: str
    #     theCharset: str
    #     table: str
    #     cols: [[str]]
    #     vals: [[str]]
    
    # return type: void
    
    conn = pymysql.connect(host=hostname,
                    user=uname,
                    db=dbname,
                    charset=theCharset,
                    cursorclass=pymysql.cursors.DictCursor)

    try:
        with conn.cursor() as cursor:
            with warnings.catch_warnings():
                
                warnings.simplefilter("ignore")
                
                sql = 'SET sql_mode = ""'
                cursor.execute(sql)
                for i in range(len(cols)):
                    if len(cols[i]) == 1:
                        sql = "INSERT IGNORE INTO {} ({}) VALUES ('{}')".format(table, cols[i][0], vals[i][0])
                    elif len(cols[i]) > 1:
                        sql = "INSERT IGNORE INTO {} ({}".format(table, cols[i][0])
                        for j in range(len(cols[i])):
                            if j != 0:
                                sql += ", {}".format(cols[i][j])
                        if not(vals[i][0] is None or type(vals[i][0]) is int or type(vals[i][0]) is float or type(vals[i][j]) is list  or type(vals[i][j]) is dict  or type(vals[i][j]) is tuple):
                        # if type(vals[i][0]) is str:
                            sql += ") VALUES ('{}'".format(pymysql.escape_string(vals[i][0]))
                        else:
                            sql += ") VALUES ('{}'".format(vals[i][0])
                        for j in range(len(cols[i])):
                            if j != 0:
                                if not(vals[i][j] is None or type(vals[i][j]) is int or type(vals[i][j]) is float or type(vals[i][j]) is list or type(vals[i][j]) is dict or type(vals[i][j]) is tuple):
                                # if type(vals[i][j]) is str:
                                    sql += ", '{}'".format(pymysql.escape_string(vals[i][j]))
                                elif type(vals[i][j]) is list or type(vals[i][j]) is dict or type(vals[i][j]) is tuple:
                                    sql += ", 'error'"
                                else:
                                    sql += ", '{}'".format(vals[i][j])                            
                        sql += ")"
                    
                    # pprint.pprint(sql)

                    cursor.execute(sql)

        conn.commit()
    finally:
        conn.close()


def prepareRequestValsArray(cols, request_type, valsarr):
    
    newArr = []
    newCols = []
    for item in valsarr:
        newArr.append([request_type, item])
        newCols.append(cols)
    
    # pprint.pprint([newCols, newArr])

    return [newCols, newArr]







def selectFromDB(hostname, uname, dbname, theCharset, table, cols, where):

    # args types:
    #     hostname: str
    #     uname: str
    #     dbname: str
    #     theCharset: str
    #     table: str
    #     cols: [str]
    #     where: str
    #       eg. "WHERE id REGEXP '.'"

    # return type: [{}]
    
    conn = pymysql.connect(host=hostname,
                    user=uname,
                    db=dbname,
                    charset=theCharset,
                    cursorclass=pymysql.cursors.DictCursor)

    result = None
    try:
        with conn.cursor() as cursor:
            if len(cols) == 1:
                sql = "SELECT {} FROM {} {}".format(cols[0], table, where)
            elif len(cols) > 1:
                sql = "SELECT {}".format(cols[0])
                for i in range(len(cols)):
                    if i != 0:
                        sql += ", {}".format(cols[i])
                sql += " FROM {} {}".format(table, where)
            
            cursor.execute(sql)
            result = cursor.fetchall()
    except:
        1 + 1
    finally:
        conn.close()

    return result


def getLatestTweetID(screen_name):
    
    latest = selectFromDB('localhost', USER_NAME, 'twigrapher', 'utf8mb4', 'tweets', ['id_str'], "WHERE user_screen_name = '{}' ORDER BY id_str DESC LIMIT 1".format(screen_name))

    if type(latest) != tuple:
        obj = latest[0]
        return obj['id_str']
    else:
        return None

# calls 1 time: twitter API users/lookup
def getFavCountDiff(screen_name):

    previous_fav_count = 0

    try:
        previous_fav_count = selectFromDB('localhost', USER_NAME, 'twigrapher', 'utf8mb4', 'users', ['fav_count'], "WHERE user_screen_name = '{}'".format(screen_name))[0]['fav_count']
    except:
        1 + 1
        
    url = 'https://api.twitter.com/1.1/users/lookup.json'
    url += '?screen_name={}'.format(screen_name)
    
    user = json.loads(oauth_req(url).decode('utf-8'))
    
    user_json = user[0] 
    user_str = json.dumps(user_json, ensure_ascii=False)

    addToUsers([user_str], screen_name)

    current_fav_count = user_json.get('favourites_count')

    # print(previous_fav_count)
    # print(current_fav_count)

    update_last_user_fetch_time(screen_name)

    return [current_fav_count - previous_fav_count, current_fav_count, previous_fav_count]


# calls 1 time: twitter API users/lookup.json
def addToFollowings(screen_name, ff_profiles, f_or_f):

    if f_or_f == 'getFriends':
        

        url = 'https://api.twitter.com/1.1/users/lookup.json'
        url += '?screen_name={}'.format(screen_name)
        
        follower = json.loads(oauth_req(url).decode('utf-8'))

        cols = []
        vals = []
        for i in range(len(ff_profiles)):
            cols.append(['follower_id', 'follower_screen_name', 'follower_name', 'followee_id', 'followee_screen_name', 'followee_name'])

        for i in range(len(ff_profiles)):
            ff_json = json.loads(ff_profiles[i])
            vals.append([int(follower[0].get('id_str')), screen_name, follower[0].get('name'), int(ff_json.get('id_str')), ff_json.get('screen_name'), ff_json.get('name')])

        insertToDB('localhost', USER_NAME, 'twigrapher', 'utf8mb4', 'followings', cols, vals)
    elif f_or_f == 'getFollowers':
        

        url = 'https://api.twitter.com/1.1/users/lookup.json'
        url += '?screen_name={}'.format(screen_name)
        
        followee = json.loads(oauth_req(url).decode('utf-8'))


        cols = []
        vals = []
        for i in range(len(ff_profiles)):
            cols.append(['followee_id', 'followee_screen_name', 'followee_name', 'follower_id', 'follower_screen_name', 'follower_name'])

        for i in range(len(ff_profiles)):
            ff_json = json.loads(ff_profiles[i])            
            vals.append([int(followee[0].get('id_str')), screen_name, followee[0].get('name'), int(ff_json.get('id_str')), ff_json.get('screen_name'), ff_json.get('name')])

        insertToDB('localhost', USER_NAME, 'twigrapher', 'utf8mb4', 'followings', cols, vals)

def addToUsers(user, screen_name):

    request = prepareRequestValsArray(['request_type', 'json_col'],'getAllNewFriendsByScreenName', user)
    insertToDB('localhost', USER_NAME, 'twigrapher', 'utf8mb4', 'AllFromTwitterAPI', request[0], request[1])

    profiles = selectFromDB('localhost', USER_NAME, 'twigrapher', 'utf8mb4', 'AllFromTwitterAPI', ['id', 'json_col', 'extracted'], "WHERE extracted = 0 AND request_type = 'getAllNewFriendsByScreenName'")
    req = formRequestArray(profiles, 'getAllNewFriendsByScreenName', screen_name)
    insertToDB('localhost', USER_NAME, 'twigrapher', 'utf8mb4', 'users', req[0], req[1])
    updateExtractedFlag('localhost', USER_NAME, 'twigrapher', 'utf8mb4', 'AllFromTwitterAPI', [['extracted']], [[1]], "WHERE extracted = 0  AND request_type = 'getAllNewFriendsByScreenName'")


def listExtract(list, screen_name):
    
    # args type: [{}] (array of full data of tweets returned from AllFromTwitterAPI DB using selectFromDB())
    # return type: [cols[],vals[]] (extracted parts of list data)

    jsonCol = list["json_col"]
    jsoned = json.loads(jsonCol)


    cols = [\
        "is_from_twitter",\
        "subscribed_by",\
        
        "id_str",\
        "name",\
        "uri",\
        "subscriber_count",\
        "member_count",\
        "mode",\
        "description",\
        "slug",\
        "full_name",\
        "created_at",\
        "following",\
        "user"\
    ]

    vals = []

    vals.append(1)

    try:
        vals.append(screen_name)
    except:
        vals.append(None)
    

    try:
        vals.append(int(jsoned['id_str']))
    except:
        vals.append(None)
    try:
        vals.append(jsoned['name'])
    except:
        vals.append(None)
    try:
        vals.append(jsoned['uri'])
    except:
        vals.append(None)
    try:
        vals.append(jsoned['subscriber_count'])
    except:
        vals.append(None)
    try:
        vals.append(jsoned['member_count'])
    except:
        vals.append(None)
    try:
        vals.append(jsoned['mode'])
    except:
        vals.append(None)
    try:
        vals.append(jsoned['description'])
    except:
        vals.append(None)
    try:
        vals.append(jsoned['slug'])
    except:
        vals.append(None)
    try:
        vals.append(jsoned['full_name'])
    except:
        vals.append(None)
    try:
        vals.append(convertTime(jsoned['created_at']))
    except:
        vals.append(None)
    try:
        vals.append(convertToTinyInt(jsoned['following']))
    except:
        vals.append(None)
    try:
        vals.append(json.dumps(jsoned['user'], ensure_ascii=False))
    except:
        vals.append(None)

    return [cols, vals]

def tweetExtract(tw):
    
    # args type: [{}] (array of full data of tweets returned from AllFromTwitterAPI DB using selectFromDB())
    # return type: [cols[],vals[]] (extracted parts of tweet data)
  
    jsonCol = tw["json_col"]
    jsoned = json.loads(jsonCol)

    cols = [\
        "id_str",\
        "full_text",\
        "created_at",\

        "source",\
        "in_reply_to_status_id_str",\
        "in_reply_to_user_id_str",\
        "in_reply_to_screen_name",\

        "is_quote_status",\
        "quoted_status_id_str",\
        "quoted_status",\

        "favorited",\
        "retweeted",\
        "retweet_count",\
        "favorite_count",\

        "possibly_sensitive",\
        "filter_level",\

        "lang",\




        "user_id_str",\
        "user_name",\
        "user_screen_name",\
        "user_location",\
        "user_url",\
        "user_description",\
        "user_protected",\
        "user_verified",\
        "user_followers_count",\
        "user_friends_count",\
        "user_listed_count",\
        "user_favourites_count",\
        "user_statuses_count",\
        "user_created_at",\
        "user_profile_banner_url",\
        "user_profile_image_url_https",\
        "user_withheld_in_countries",\





        "place_place_type",\
        "place_name",\
        "place_full_name",\
        "place_country_code",\
        "place_country",\
        "place_bounding_box_coordinates_1Long",\
        "place_bounding_box_coordinates_1Lat",\
        "place_bounding_box_coordinates_2Long",\
        "place_bounding_box_coordinates_2Lat",\
        "place_bounding_box_coordinates_3Long",\
        "place_bounding_box_coordinates_3Lat",\
        "place_bounding_box_coordinates_4Long",\
        "place_bounding_box_coordinates_4Lat",\
        "place_bounding_box_type",\

        "coordinates_type",\
        "coordinates_coordinates_Long",\
        "coordinates_coordinates_Lat",\






        "entities_hashtags0_indices_start",\
        "entities_hashtags0_indices_end",\
        "entities_hashtags0_text",\

        "entities_hashtags1_indices_start",\
        "entities_hashtags1_indices_end",\
        "entities_hashtags1_text",\

        "entities_hashtags2_indices_start",\
        "entities_hashtags2_indices_end",\
        "entities_hashtags2_text",\
            
        "entities_hashtags3_indices_start",\
        "entities_hashtags3_indices_end",\
        "entities_hashtags3_text",\

        "entities_hashtags4_indices_start",\
        "entities_hashtags4_indices_end",\
        "entities_hashtags4_text",\

        "entities_hashtags5_indices_start",\
        "entities_hashtags5_indices_end",\
        "entities_hashtags5_text",\

        "entities_hashtags6_indices_start",\
        "entities_hashtags6_indices_end",\
        "entities_hashtags6_text",\
            
        "entities_hashtags7_indices_start",\
        "entities_hashtags7_indices_end",\
        "entities_hashtags7_text",\


        "entities_media0_display_url",\
        "entities_media0_expanded_url",\
        "entities_media0_id_str",\
        "entities_media0_indices_start",\
        "entities_media0_indices_end",\
        "entities_media0_media_url",\
        "entities_media0_media_url_https",\
        "entities_media0_type",\
        "entities_media0_url",\

        "entities_media1_display_url",\
        "entities_media1_expanded_url",\
        "entities_media1_id_str",\
        "entities_media1_indices_start",\
        "entities_media1_indices_end",\
        "entities_media1_media_url",\
        "entities_media1_media_url_https",\
        "entities_media1_type",\
        "entities_media1_url",\

        "entities_media2_display_url",\
        "entities_media2_expanded_url",\
        "entities_media2_id_str",\
        "entities_media2_indices_start",\
        "entities_media2_indices_end",\
        "entities_media2_media_url",\
        "entities_media2_media_url_https",\
        "entities_media2_type",\
        "entities_media2_url",\

        "entities_media3_display_url",\
        "entities_media3_expanded_url",\
        "entities_media3_id_str",\
        "entities_media3_indices_start",\
        "entities_media3_indices_end",\
        "entities_media3_media_url",\
        "entities_media3_media_url_https",\
        "entities_media3_type",\
        "entities_media3_url",\


        "entities_urls0_indices_start",\
        "entities_urls0_indices_end",\
        "entities_urls0_url",\
        "entities_urls0_display_url",\
        "entities_urls0_expanded_url",\

        "entities_urls1_indices_start",\
        "entities_urls1_indices_end",\
        "entities_urls1_url",\
        "entities_urls1_display_url",\
        "entities_urls1_expanded_url",\

        "entities_urls2_indices_start",\
        "entities_urls2_indices_end",\
        "entities_urls2_url",\
        "entities_urls2_display_url",\
        "entities_urls2_expanded_url",\

        "entities_urls3_indices_start",\
        "entities_urls3_indices_end",\
        "entities_urls3_url",\
        "entities_urls3_display_url",\
        "entities_urls3_expanded_url",\



        "entities_user_mentions0_name",\
        "entities_user_mentions0_indices_start",\
        "entities_user_mentions0_indices_end",\
        "entities_user_mentions0_screen_name",\
        "entities_user_mentions0_id_str",\

        "entities_user_mentions1_name",\
        "entities_user_mentions1_indices_start",\
        "entities_user_mentions1_indices_end",\
        "entities_user_mentions1_screen_name",\
        "entities_user_mentions1_id_str",\

        "entities_user_mentions2_name",\
        "entities_user_mentions2_indices_start",\
        "entities_user_mentions2_indices_end",\
        "entities_user_mentions2_screen_name",\
        "entities_user_mentions2_id_str",\
            
        "entities_user_mentions3_name",\
        "entities_user_mentions3_indices_start",\
        "entities_user_mentions3_indices_end",\
        "entities_user_mentions3_screen_name",\
        "entities_user_mentions3_id_str",\

        "entities_user_mentions4_name",\
        "entities_user_mentions4_indices_start",\
        "entities_user_mentions4_indices_end",\
        "entities_user_mentions4_screen_name",\
        "entities_user_mentions4_id_str",\

        "entities_user_mentions5_name",\
        "entities_user_mentions5_indices_start",\
        "entities_user_mentions5_indices_end",\
        "entities_user_mentions5_screen_name",\
        "entities_user_mentions5_id_str",\

        "entities_user_mentions6_name",\
        "entities_user_mentions6_indices_start",\
        "entities_user_mentions6_indices_end",\
        "entities_user_mentions6_screen_name",\
        "entities_user_mentions6_id_str",\
            
        "entities_user_mentions7_name",\
        "entities_user_mentions7_indices_start",\
        "entities_user_mentions7_indices_end",\
        "entities_user_mentions7_screen_name",\
        "entities_user_mentions7_id_str",\


        "entities_symbols_indices_start",\
        "entities_symbols_indices_end",\
        "entities_symbols_text",\

        "entities_polls_option1_text",\
        "entities_polls_option2_text",\
        "entities_polls_option3_text",\
        "entities_polls_option4_text",\
        "entities_polls_end_datetime",\
        "entities_polls_duration_minutes",\

        "extended_entities_media0_media_url_https",\
        "extended_entities_media0_type",\
        "extended_entities_media1_media_url_https",\
        "extended_entities_media1_type",\
        "extended_entities_media2_media_url_https",\
        "extended_entities_media2_type",\
        "extended_entities_media3_media_url_https",\
        "extended_entities_media3_type"\
    ]

    vals = []

    vals.append(int(jsoned['id_str']))
    vals.append(jsoned['full_text'])
    vals.append(convertTime(jsoned['created_at']))

    try:
        vals.append(jsoned['source'])
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned['in_reply_to_status_id_str']))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned['in_reply_to_user_id_str']))
    except:
        vals.append(None)
    try:
        vals.append(jsoned['in_reply_to_screen_name'])
    except:
        vals.append(None)



    try:
        vals.append(convertToTinyInt(jsoned['is_quote_status']))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned['quoted_status_id_str']))
    except:
        vals.append(None)
    try:
        vals.append(json.dumps(jsoned['quoted_status'], ensure_ascii=False))
    except:
        vals.append(None)


    try:
        vals.append(convertToTinyInt(jsoned['favorited']))
    except:
        vals.append(None)
    try:
        vals.append(convertToTinyInt(jsoned['retweeted']))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned['retweet_count']))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned['favorite_count']))
    except:
        vals.append(None)


    try:
        vals.append(convertToTinyInt(jsoned['possibly_sensitive']))
    except:
        vals.append(None)
    try:
        vals.append(jsoned['filter_level'])
    except:
        vals.append(None)
    try:
        vals.append(jsoned['lang'])
    except:
        vals.append(None)






    try:
        vals.append(int(jsoned.get('user').get('id_str')))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('user').get('name'))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('user').get('screen_name'))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('user').get('location'))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('user').get('url'))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('user').get('description'))
    except:
        vals.append(None)
    try:
        vals.append(convertToTinyInt(jsoned.get('user').get('user_protected')))
    except:
        vals.append(None)
    try:
        vals.append(convertToTinyInt(jsoned.get('user').get('user_verified')))
    except:
        vals.append(None)


    try:
        vals.append(int(jsoned.get('user').get('followers_count')))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('user').get('friends_count')))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('user').get('listed_count')))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('user').get('favourites_count')))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('user').get('statuses_count')))
    except:
        vals.append(None)

    try:
        vals.append(convertTime(jsoned.get('user').get('created_at')))
    except:
        vals.append(None)

    try:
        vals.append(jsoned.get('user').get('profile_banner_url'))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('user').get('profile_image_url_https'))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('user').get('withheld_in_countries'))
    except:
        vals.append(None)





    try:
        vals.append(jsoned.get('place').get('place_type'))
    except:
        vals.append(None)
    try: 
        vals.append(jsoned.get('place').get('name'))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('place').get('full_name'))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('place').get('country_code'))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('place').get('country'))
    except:
        vals.append(None)


    try:
        vals.append(float(jsoned.get('place').get('bounding_box').get('coordinates')[0][0][0]))
    except:
        vals.append(None)
    try:
        vals.append(float(jsoned.get('place').get('bounding_box').get('coordinates')[0][0][1]))
    except:
        vals.append(None)
    try:
        vals.append(float(jsoned.get('place').get('bounding_box').get('coordinates')[0][1][0]))
    except:
        vals.append(None)
    try:
        vals.append(float(jsoned.get('place').get('bounding_box').get('coordinates')[0][1][1]))
    except:
        vals.append(None)
    try:
        vals.append(float(jsoned.get('place').get('bounding_box').get('coordinates')[0][2][0]))
    except:
        vals.append(None)
    try:
        vals.append(float(jsoned.get('place').get('bounding_box').get('coordinates')[0][2][1]))
    except:
        vals.append(None)
    try:
        vals.append(float(jsoned.get('place').get('bounding_box').get('coordinates')[0][3][0]))
    except:
        vals.append(None)
    try:
        vals.append(float(jsoned.get('place').get('bounding_box').get('coordinates')[0][3][1]))
    except:
        vals.append(None)

    try:
        vals.append(jsoned.get('place').get('bounding_box').get('type'))
    except:
        vals.append(None)





    try:
        vals.append(jsoned.get('coordinates').get('type'))
    except:
        vals.append(None)
    try:
        vals.append(float(jsoned.get('coordinates').get('coordinates')[0]))
    except:
        vals.append(None)
    try:
        vals.append(float(jsoned.get('coordinates').get('coordinates')[1]))
    except:
        vals.append(None)





    try:
        vals.append(int(jsoned.get('entities').get('hashtags')[0].get('indices')[0]))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('entities').get('hashtags')[0].get('indices')[1]))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('entities').get('hashtags')[0].get('text'))
    except:
        vals.append(None)

    try:
        vals.append(int(jsoned.get('entities').get('hashtags')[1].get('indices')[0]))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('entities').get('hashtags')[1].get('indices')[1]))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('entities').get('hashtags')[1].get('text'))
    except:
        vals.append(None)

    try:
        vals.append(int(jsoned.get('entities').get('hashtags')[2].get('indices')[0]))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('entities').get('hashtags')[2].get('indices')[1]))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('entities').get('hashtags')[2].get('text'))
    except:
        vals.append(None)

    try:
        vals.append(int(jsoned.get('entities').get('hashtags')[3].get('indices')[0]))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('entities').get('hashtags')[3].get('indices')[1]))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('entities').get('hashtags')[3].get('text'))
    except:
        vals.append(None)

    try:
        vals.append(int(jsoned.get('entities').get('hashtags')[4].get('indices')[0]))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('entities').get('hashtags')[4].get('indices')[1]))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('entities').get('hashtags')[4].get('text'))
    except:
        vals.append(None)

    try:
        vals.append(int(jsoned.get('entities').get('hashtags')[5].get('indices')[0]))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('entities').get('hashtags')[5].get('indices')[1]))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('entities').get('hashtags')[5].get('text'))
    except:
        vals.append(None)

    try:
        vals.append(int(jsoned.get('entities').get('hashtags')[6].get('indices')[0]))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('entities').get('hashtags')[6].get('indices')[1]))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('entities').get('hashtags')[6].get('text'))
    except:
        vals.append(None)

    try:
        vals.append(int(jsoned.get('entities').get('hashtags')[7].get('indices')[0]))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('entities').get('hashtags')[7].get('indices')[1]))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('entities').get('hashtags')[7].get('text'))
    except:
        vals.append(None)



    try:
        vals.append(jsoned.get('entities').get('media')[0].get('display_url'))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('entities').get('media')[0].get('expanded_url'))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('entities').get('media')[0].get('id_str')))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('entities').get('media')[0].get('indices')[0]))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('entities').get('media')[0].get('indices')[1]))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('entities').get('media')[0].get('media_url'))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('entities').get('media')[0].get('media_url_https'))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('entities').get('media')[0].get('type'))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('entities').get('media')[0].get('url'))
    except:
        vals.append(None)


    try:
        vals.append(jsoned.get('entities').get('media')[1].get('display_url'))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('entities').get('media')[1].get('expanded_url'))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('entities').get('media')[1].get('id_str')))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('entities').get('media')[1].get('indices')[0]))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('entities').get('media')[1].get('indices')[1]))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('entities').get('media')[1].get('media_url'))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('entities').get('media')[1].get('media_url_https'))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('entities').get('media')[1].get('type'))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('entities').get('media')[1].get('url'))
    except:
        vals.append(None)


    try:
        vals.append(jsoned.get('entities').get('media')[2].get('display_url'))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('entities').get('media')[2].get('expanded_url'))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('entities').get('media')[2].get('id_str')))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('entities').get('media')[2].get('indices')[0]))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('entities').get('media')[2].get('indices')[1]))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('entities').get('media')[2].get('media_url'))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('entities').get('media')[2].get('media_url_https'))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('entities').get('media')[2].get('type'))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('entities').get('media')[2].get('url'))
    except:
        vals.append(None)


    try:
        vals.append(jsoned.get('entities').get('media')[3].get('display_url'))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('entities').get('media')[3].get('expanded_url'))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('entities').get('media')[3].get('id_str')))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('entities').get('media')[3].get('indices')[0]))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('entities').get('media')[3].get('indices')[1]))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('entities').get('media')[3].get('media_url'))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('entities').get('media')[3].get('media_url_https'))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('entities').get('media')[3].get('type'))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('entities').get('media')[3].get('url'))
    except:
        vals.append(None)




    try:
        vals.append(int(jsoned.get('entities').get('urls')[0].get('indices')[0]))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('entities').get('urls')[0].get('indices')[1]))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('entities').get('urls')[0].get('url'))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('entities').get('urls')[0].get('display_url'))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('entities').get('urls')[0].get('expanded_url'))
    except:
        vals.append(None)


    try:
        vals.append(int(jsoned.get('entities').get('urls')[1].get('indices')[0]))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('entities').get('urls')[1].get('indices')[1]))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('entities').get('urls')[1].get('url'))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('entities').get('urls')[1].get('display_url'))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('entities').get('urls')[1].get('expanded_url'))
    except:
        vals.append(None)


    try:
        vals.append(int(jsoned.get('entities').get('urls')[2].get('indices')[0]))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('entities').get('urls')[2].get('indices')[1]))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('entities').get('urls')[2].get('url'))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('entities').get('urls')[2].get('display_url'))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('entities').get('urls')[2].get('expanded_url'))
    except:
        vals.append(None)


    try:
        vals.append(int(jsoned.get('entities').get('urls')[3].get('indices')[0]))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('entities').get('urls')[3].get('indices')[1]))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('entities').get('urls')[3].get('url'))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('entities').get('urls')[3].get('display_url'))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('entities').get('urls')[3].get('expanded_url'))
    except:
        vals.append(None)





    try:
        vals.append(jsoned.get('entities').get('user_mentions')[0].get('name'))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('entities').get('user_mentions')[0].get('indices')[0]))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('entities').get('user_mentions')[0].get('indices')[1]))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('entities').get('user_mentions')[0].get('screen_name'))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('entities').get('user_mentions')[0].get('id_str')))
    except:
        vals.append(None)


    try:
        vals.append(jsoned.get('entities').get('user_mentions')[1].get('name'))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('entities').get('user_mentions')[1].get('indices')[0]))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('entities').get('user_mentions')[1].get('indices')[1]))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('entities').get('user_mentions')[1].get('screen_name'))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('entities').get('user_mentions')[1].get('id_str')))
    except:
        vals.append(None)


    try:
        vals.append(jsoned.get('entities').get('user_mentions')[2].get('name'))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('entities').get('user_mentions')[2].get('indices')[0]))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('entities').get('user_mentions')[2].get('indices')[1]))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('entities').get('user_mentions')[2].get('screen_name'))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('entities').get('user_mentions')[2].get('id_str')))
    except:
        vals.append(None)


    try:
        vals.append(jsoned.get('entities').get('user_mentions')[3].get('name'))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('entities').get('user_mentions')[3].get('indices')[0]))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('entities').get('user_mentions')[3].get('indices')[1]))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('entities').get('user_mentions')[3].get('screen_name'))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('entities').get('user_mentions')[3].get('id_str')))
    except:
        vals.append(None)


    try:
        vals.append(jsoned.get('entities').get('user_mentions')[4].get('name'))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('entities').get('user_mentions')[4].get('indices')[0]))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('entities').get('user_mentions')[4].get('indices')[1]))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('entities').get('user_mentions')[4].get('screen_name'))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('entities').get('user_mentions')[4].get('id_str')))
    except:
        vals.append(None)


    try:
        vals.append(jsoned.get('entities').get('user_mentions')[5].get('name'))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('entities').get('user_mentions')[5].get('indices')[0]))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('entities').get('user_mentions')[5].get('indices')[1]))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('entities').get('user_mentions')[5].get('screen_name'))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('entities').get('user_mentions')[5].get('id_str')))
    except:
        vals.append(None)


    try:
        vals.append(jsoned.get('entities').get('user_mentions')[6].get('name'))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('entities').get('user_mentions')[6].get('indices')[0]))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('entities').get('user_mentions')[6].get('indices')[1]))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('entities').get('user_mentions')[6].get('screen_name'))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('entities').get('user_mentions')[6].get('id_str')))
    except:
        vals.append(None)


    try:
        vals.append(jsoned.get('entities').get('user_mentions')[7].get('name'))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('entities').get('user_mentions')[7].get('indices')[0]))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('entities').get('user_mentions')[7].get('indices')[1]))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('entities').get('user_mentions')[7].get('screen_name'))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('entities').get('user_mentions')[7].get('id_str')))
    except:
        vals.append(None)





    try:
        vals.append(int(jsoned.get('entities').get('symbols')[0].get('indices')[0]))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('entities').get('symbols')[0].get('indices')[1]))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('entities').get('symbols')[0].get('text'))
    except:
        vals.append(None)

    try:
        vals.append(jsoned.get('entities').get('polls')[0].get('options')[0].get('text'))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('entities').get('polls')[0].get('options')[1].get('text'))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('entities').get('polls')[0].get('options')[2].get('text'))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('entities').get('polls')[0].get('options')[3].get('text'))
    except:
        vals.append(None)

    try:
        vals.append(convertTime(jsoned.get('entities').get('polls')[0].get('end_datetime')))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('entities').get('polls')[0].get('duration_minutes')))
    except:
        vals.append(None)


    try:
        vals.append(jsoned.get('extended_entities').get('media')[0].get('media_url_https'))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('extended_entities').get('media')[0].get('type'))
    except:
        vals.append(None)

    try:
        vals.append(jsoned.get('extended_entities').get('media')[1].get('media_url_https'))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('extended_entities').get('media')[1].get('type'))
    except:
        vals.append(None)

    try:
        vals.append(jsoned.get('extended_entities').get('media')[2].get('media_url_https'))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('extended_entities').get('media')[2].get('type'))
    except:
        vals.append(None)

    try:
        vals.append(jsoned.get('extended_entities').get('media')[3].get('media_url_https'))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('extended_entities').get('media')[3].get('type'))
    except:
        vals.append(None)


    return [cols, vals]

def userExtract(user):
    
    # args type: [{}] (array of full data of tweets returned from AllFromTwitterAPI DB using selectFromDB())
    # return type: [cols[],vals[]] (extracted parts of tweet data)
  
    jsonCol = user["json_col"]
    jsoned = json.loads(jsonCol)

    cols = [\
        "user_id_str",\
        "user_name",\
        "user_screen_name",\
        "user_location",\
        "user_url",\
        "user_description",\
        "user_protected",\
        "user_verified",\
        "user_followers_count",\
        "user_friends_count",\
        "user_listed_count",\
        "user_favourites_count",\
        "user_statuses_count",\
        "user_created_at",\
        "user_profile_banner_url",\
        "user_profile_image_url_https",\
        "user_withheld_in_countries",\
    ]

    vals = []

    try:
        vals.append(int(jsoned.get('id_str')))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('name'))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('screen_name'))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('location'))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('url'))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('description'))
    except:
        vals.append(None)
    try:
        vals.append(convertToTinyInt(jsoned.get('user_protected')))
    except:
        vals.append(None)
    try:
        vals.append(convertToTinyInt(jsoned.get('user_verified')))
    except:
        vals.append(None)


    try:
        vals.append(int(jsoned.get('followers_count')))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('friends_count')))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('listed_count')))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('favourites_count')))
    except:
        vals.append(None)
    try:
        vals.append(int(jsoned.get('statuses_count')))
    except:
        vals.append(None)

    try:
        vals.append(convertTime(jsoned.get('created_at')))
    except:
        vals.append(None)

    try:
        vals.append(jsoned.get('profile_banner_url'))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('profile_image_url_https'))
    except:
        vals.append(None)
    try:
        vals.append(jsoned.get('withheld_in_countries'))
    except:
        vals.append(None)
    

    return [cols, vals]


def convertTime(twTime):
    
    ts = time.strftime('%Y-%m-%d %H:%M:%S', time.strptime(twTime,'%a %b %d %H:%M:%S +0000 %Y'))
    return ts

def convertToTinyInt(boolval):
    
    if boolval == 'true':
        return 1
    else:
        return 0

def formRequestArray(tws, req, by_screen_name = None):
    
    if req == 'getAllNewTweetsByScreenName':
        
        cols = []
        vals = []
        for i in range(len(tws)):
            extracted = tweetExtract(tws[i])
            cols.append(extracted[0])
            vals.append(extracted[1])
                
        # pprint.pprint(vals)

        return [cols, vals]
    elif req == 'getAllNewFriendsByScreenName' or req == 'getAllNewFollowersByScreenName':

        cols = []
        vals = []
        for i in range(len(tws)):
            extracted = userExtract(tws[i])
            cols.append(extracted[0])
            vals.append(extracted[1])
        
        return [cols, vals]
    elif req == 'getAllNewFavsByScreenName':
        
        cols = []
        vals = []

        for i in range(len(tws)):
            extracted = tweetExtract(tws[i])
            
            extracted[0].append('fav_by_screen_name')
            extracted[1].append("{}".format(by_screen_name))
            cols.append(extracted[0])
            vals.append(extracted[1])
        
        # pprint.pprint(vals)

        return [cols, vals]
    elif req == 'getAllListsByScreenName':
        
        cols = []
        vals = []

        for i in range(len(tws)):
            extracted = listExtract(tws[i], by_screen_name)
            extracted[0].append('members')
            # extracted[1][2] is list id
            extracted[1].append(json.dumps(getListMembers(extracted[1][2]), ensure_ascii=False))
            cols.append(extracted[0])
            vals.append(extracted[1])

        
        # pprint.pprint(vals)

        return [cols, vals]


def tweetExtractTweetID(tw):
    
    # args type: {} (full data of tweet)
    # return type: str (tweet ID)
  
    tw0 = tw[0]
    jsonCol = tw0['json_col']
    jsoned = json.loads(jsonCol)

    id = jsoned['id_str']
   
    # print(id)

    return id

def updateDB(hostname, uname, dbname, theCharset, table, cols, vals, where):
   
    # args types:
    #     hostname: str
    #     uname: str
    #     dbname: str
    #     theCharset: str
    #     table: str
    #     cols: [[str]]
    #     vals: [[str]]
    #     where: str
    #       eg. "WHERE id REGEXP '.'"
    
    # return type: void
    
    conn = pymysql.connect(host=hostname,
                    user=uname,
                    db=dbname,
                    charset=theCharset,
                    cursorclass=pymysql.cursors.DictCursor)

    try:
        with conn.cursor() as cursor:
            with warnings.catch_warnings():
                
                warnings.simplefilter("ignore")
                
                sql = 'SET sql_mode = ""'
                cursor.execute(sql)
                for i in range(len(cols)):
                    if len(cols[i]) == 1:
                        sql = "UPDATE IGNORE {} SET {} = {} {}".format(table, cols[i][0], vals[i][0], where)
                    elif len(cols[i]) > 1:
                        sql = "UPDATE IGNORE {} SET {} = {}".format(table, cols[i][0], vals[i][0])
                        for j in range(len(cols[i])):
                            if j != 0:
                                sql += ", {} = {}".format(cols[i][j], vals[i][j])
                        sql += " {}".format(where)
                    
                    # pprint.pprint(sql)

                    cursor.execute(sql)

        conn.commit()
    finally:
        conn.close()

def updateExtractedFlag(hostname, uname, dbname, theCharset, table, cols, vals, where):

        updateDB(hostname, uname, dbname, theCharset, table, cols, vals, where)

# also does update_last_fav_fetch_time
def updateFavCount(screen_name):

    current_fav_count = selectFromDB('localhost', USER_NAME, 'twigrapher', 'utf8mb4', 'users', ['user_favourites_count'], "WHERE user_screen_name = '{}'".format(screen_name))

    current_time = time.strftime('%Y-%m-%d %H:%M:%S', time.strptime(str(datetime.datetime.now()),'%Y-%m-%d %H:%M:%S.%f'))

    updateDB('localhost', USER_NAME, 'twigrapher', 'utf8mb4', 'users', [['fav_count', 'last_fav_fetch_time']], [[current_fav_count[0]['user_favourites_count'], "'{}'".format(current_time)]], "WHERE user_screen_name = '{}'".format(screen_name))

# calls 1 time: twitter API users/lookup.json
# also makes sure the user is in the user list
def update_last_tweet_fetch_time(screen_name):

    current_time = time.strftime('%Y-%m-%d %H:%M:%S', time.strptime(str(datetime.datetime.now()),'%Y-%m-%d %H:%M:%S.%f'))

    last_tweet_fetch_time = current_time

    try:
        last_tweet_fetch_time = selectFromDB('localhost', USER_NAME, 'twigrapher', 'utf8mb4', 'users', ['last_tweet_fetch_time'], "WHERE user_screen_name = '{}'".format(screen_name))[0]['last_tweet_fetch_time']
    except:
        1 + 1
        
    if last_tweet_fetch_time == current_time:

        url = 'https://api.twitter.com/1.1/users/lookup.json'
        url += '?screen_name={}'.format(screen_name)
        
        user = json.loads(oauth_req(url).decode('utf-8'))
        
        user_json = user[0] 
        user_str = json.dumps(user_json, ensure_ascii=False)

        addToUsers([user_str], screen_name)

    
    updateDB('localhost', USER_NAME, 'twigrapher', 'utf8mb4', 'users', [['last_tweet_fetch_time']], [["'{}'".format(current_time)]], "WHERE user_screen_name = '{}'".format(screen_name))

    update_last_user_fetch_time(screen_name)

def update_last_user_fetch_time(screen_name):

    current_time = time.strftime('%Y-%m-%d %H:%M:%S', time.strptime(str(datetime.datetime.now()),'%Y-%m-%d %H:%M:%S.%f'))
    
    updateDB('localhost', USER_NAME, 'twigrapher', 'utf8mb4', 'users', [['last_user_fetch_time']], [["'{}'".format(current_time)]], "WHERE user_screen_name = '{}'".format(screen_name))

# calls 1 time: twitter API users/lookup.json
# also makes sure the user is in the user list, and update_last_user_fetch_time.
def update_last_followers_fetch_time(screen_name):

    current_time = time.strftime('%Y-%m-%d %H:%M:%S', time.strptime(str(datetime.datetime.now()),'%Y-%m-%d %H:%M:%S.%f'))

    last_followers_fetch_time = current_time

    try:
        last_followers_fetch_time = selectFromDB('localhost', USER_NAME, 'twigrapher', 'utf8mb4', 'users', ['last_followers_fetch_time'], "WHERE user_screen_name = '{}'".format(screen_name))[0]['last_followers_fetch_time']
    except:
        1 + 1
        
    if last_followers_fetch_time == current_time:


        url = 'https://api.twitter.com/1.1/users/lookup.json'
        url += '?screen_name={}'.format(screen_name)
        
        user = json.loads(oauth_req(url).decode('utf-8'))
        
        user_json = user[0] 
        user_str = json.dumps(user_json, ensure_ascii=False)

        addToUsers([user_str], screen_name)

    
    updateDB('localhost', USER_NAME, 'twigrapher', 'utf8mb4', 'users', [['last_followers_fetch_time']], [["'{}'".format(current_time)]], "WHERE user_screen_name = '{}'".format(screen_name))
    update_last_user_fetch_time(screen_name)

# calls 1 time: twitter API users/lookup.json
# also makes sure the user is in the user list
def update_last_friends_fetch_time(screen_name):

    current_time = time.strftime('%Y-%m-%d %H:%M:%S', time.strptime(str(datetime.datetime.now()),'%Y-%m-%d %H:%M:%S.%f'))

    last_friends_fetch_time = current_time

    try:
        last_friends_fetch_time = selectFromDB('localhost', USER_NAME, 'twigrapher', 'utf8mb4', 'users', ['last_friends_fetch_time'], "WHERE user_screen_name = '{}'".format(screen_name))[0]['last_friends_fetch_time']
    except:
        1 + 1
        
    if last_friends_fetch_time == current_time:

        
        url = 'https://api.twitter.com/1.1/users/lookup.json'
        url += '?screen_name={}'.format(screen_name)
        
        user = json.loads(oauth_req(url).decode('utf-8'))
        
        user_json = user[0] 
        user_str = json.dumps(user_json, ensure_ascii=False)

        addToUsers([user_str], screen_name)

    
    updateDB('localhost', USER_NAME, 'twigrapher', 'utf8mb4', 'users', [['last_friends_fetch_time']], [["'{}'".format(current_time)]], "WHERE user_screen_name = '{}'".format(screen_name))
    update_last_user_fetch_time(screen_name)


# tester fn
def typeOfArray(req):
    
    cols = req[0]
    vals = req[1]

    # colstype = list(map(lambda i: list(map(lambda j: type(j), i)), cols))
    valstype = list(map(lambda i: list(map(lambda j: type(j), i)), vals))

    # for i in range(len(cols)):
    #     for j in range(len(cols[i])):
    #         colstype[i][j] = type(cols[i][j])
    # for i in range(len(vals)):
    #     for j in range(len(vals[i])):
    #         valstype[i][j] = type(vals[i][j])

    result = []
    for i in range(len(cols)):
        # result.append(colstype[i])
        result.append(cols[i])
        result.append(valstype[i])

    pprint.pprint(result)



# tester -----------------------------------------------------

# tweet version done
# twitter API statuses/user_timeline: 900/15min limit: calls max 17 times
# twitter API users/lookup: 300/15min limit: calls 1 time
def getTweets(screen_name, token = ACCESS_TOKEN, token_secret = ACCESS_TOKEN_SECRET):
    
    ACCESS_TOKEN = token
    ACCESS_TOKEN_SECRET = token_secret

    # screen name と そのscreen nameによる AllFromTwitterAPI 内の最も新しいツイートID を指定して、新しいツイートをTwitter API から取得、AllFromTwitterAPIに追加
    tws = getAllNewTweetsByScreenName(screen_name, getLatestTweetID(screen_name))
    if tws is None:
        print('Not authorized.')
        return
    request = prepareRequestValsArray(['request_type', 'json_col'],'getAllNewTweetsByScreenName', tws)
    insertToDB('localhost', USER_NAME, 'twigrapher', 'utf8mb4', 'AllFromTwitterAPI', request[0], request[1])
    update_last_tweet_fetch_time(screen_name)

    # AllFromTwitterAPI から 取ってきたtweetsを tweetExtractして tweetsに格納
    tws = selectFromDB('localhost', USER_NAME, 'twigrapher', 'utf8mb4', 'AllFromTwitterAPI', ['id', 'json_col', 'extracted'], "WHERE extracted = 0 AND request_type = 'getAllNewTweetsByScreenName'")
    req = formRequestArray(tws, 'getAllNewTweetsByScreenName')
    insertToDB('localhost', USER_NAME, 'twigrapher', 'utf8mb4', 'tweets', req[0], req[1])
    updateExtractedFlag('localhost', USER_NAME, 'twigrapher', 'utf8mb4', 'AllFromTwitterAPI', [['extracted']], [[1]], "WHERE extracted = 0 AND request_type = 'getAllNewTweetsByScreenName'")

# --------------
# fav版 done
# twitter API favorites/list: 75/15min limit: calls max 11 times
# twitter API users/lookup: 300/15min limit: calls 1 time
def getFavs(screen_name, token = ACCESS_TOKEN, token_secret = ACCESS_TOKEN_SECRET):

    ACCESS_TOKEN = token
    ACCESS_TOKEN_SECRET = token_secret

    fav_count_diff = getFavCountDiff(screen_name)
    favs = getAllNewFavsByScreenName(screen_name, fav_count_diff[0])
    if favs is None:
        print('Not authorized.')
        return
    request = prepareRequestValsArray(['request_type', 'json_col'],'getAllNewFavsByScreenName', favs)
    insertToDB('localhost', USER_NAME, 'twigrapher', 'utf8mb4', 'AllFromTwitterAPI', request[0], request[1])
    updateFavCount(screen_name)

    favs = selectFromDB('localhost', USER_NAME, 'twigrapher', 'utf8mb4', 'AllFromTwitterAPI', ['id', 'json_col', 'extracted'], "WHERE extracted = 0 AND request_type = 'getAllNewFavsByScreenName'")
    req = formRequestArray(favs, 'getAllNewFavsByScreenName', screen_name)
    insertToDB('localhost', USER_NAME, 'twigrapher', 'utf8mb4', 'favs', req[0], req[1])
    updateExtractedFlag('localhost', USER_NAME, 'twigrapher', 'utf8mb4', 'AllFromTwitterAPI', [['extracted']], [[1]], "WHERE extracted = 0  AND request_type = 'getAllNewFavsByScreenName'")

# --------------
# user版 done
# twitter API friends/ids: 15/15min limit: calls max 1 time
# twitter API users/lookup: 300/15min limit: calls max 52 times
def getFriends(screen_name, token = ACCESS_TOKEN, token_secret = ACCESS_TOKEN_SECRET):

    ACCESS_TOKEN = token
    ACCESS_TOKEN_SECRET = token_secret

    user_ids = getAllNewFriendsByScreenName(screen_name)

    if user_ids is None:
        print('Not authorized.')
        return
    profiles = convertToUserProfiles(user_ids)

    addToFollowings(screen_name, profiles, 'getFriends')
    request = prepareRequestValsArray(['request_type', 'json_col'],'getAllNewFriendsByScreenName', profiles)
    insertToDB('localhost', USER_NAME, 'twigrapher', 'utf8mb4', 'AllFromTwitterAPI', request[0], request[1])

    profiles = selectFromDB('localhost', USER_NAME, 'twigrapher', 'utf8mb4', 'AllFromTwitterAPI', ['id', 'json_col', 'extracted'], "WHERE extracted = 0 AND request_type = 'getAllNewFriendsByScreenName'")
    req = formRequestArray(profiles, 'getAllNewFriendsByScreenName', screen_name)
    insertToDB('localhost', USER_NAME, 'twigrapher', 'utf8mb4', 'users', req[0], req[1])
    for user in profiles:
        jsonCol = user["json_col"]
        jsoned = json.loads(jsonCol)
        update_last_user_fetch_time(jsoned['screen_name'])
    updateExtractedFlag('localhost', USER_NAME, 'twigrapher', 'utf8mb4', 'AllFromTwitterAPI', [['extracted']], [[1]], "WHERE extracted = 0  AND request_type = 'getAllNewFriendsByScreenName'")
    update_last_friends_fetch_time(screen_name)

# twitter API followers/ids: 15/15min limit: calls max 1 time
# twitter API users/lookup: 300/15min limit: calls max 52 times
def getFollowers(screen_name, token = ACCESS_TOKEN, token_secret = ACCESS_TOKEN_SECRET):

    ACCESS_TOKEN = token
    ACCESS_TOKEN_SECRET = token_secret

    user_ids = getAllNewFollowersByScreenName(screen_name)
    if user_ids is None:
        print('Not authorized.')
        return
    profiles = convertToUserProfiles(user_ids)
    addToFollowings(screen_name, profiles, 'getFollowers')
    request = prepareRequestValsArray(['request_type', 'json_col'],'getAllNewFollowersByScreenName', profiles)
    insertToDB('localhost', USER_NAME, 'twigrapher', 'utf8mb4', 'AllFromTwitterAPI', request[0], request[1])

    profiles = selectFromDB('localhost', USER_NAME, 'twigrapher', 'utf8mb4', 'AllFromTwitterAPI', ['id', 'json_col', 'extracted'], "WHERE extracted = 0 AND request_type = 'getAllNewFollowersByScreenName'")
    req = formRequestArray(profiles, 'getAllNewFollowersByScreenName', screen_name)
    insertToDB('localhost', USER_NAME, 'twigrapher', 'utf8mb4', 'users', req[0], req[1])
    for user in profiles:
        jsonCol = user["json_col"]
        jsoned = json.loads(jsonCol)
        update_last_user_fetch_time(jsoned['screen_name'])
    updateExtractedFlag('localhost', USER_NAME, 'twigrapher', 'utf8mb4', 'AllFromTwitterAPI', [['extracted']], [[1]], "WHERE extracted = 0  AND request_type = 'getAllNewFollowersByScreenName'")
    update_last_followers_fetch_time(screen_name)

# twitter API lists/members: 900/15min limit: calls max 100 times (depends on number of lists the user has.) : 
# twitter API lists/list: 15/15min limit: calls max 1 time
def getLists(screen_name, token = ACCESS_TOKEN, token_secret = ACCESS_TOKEN_SECRET):

    ACCESS_TOKEN = token
    ACCESS_TOKEN_SECRET = token_secret

    lists = getAllListsByScreenName(screen_name)
    request = prepareRequestValsArray(['request_type', 'json_col'],'getAllListsByScreenName', lists)
    insertToDB('localhost', USER_NAME, 'twigrapher', 'utf8mb4', 'AllFromTwitterAPI', request[0], request[1])

    lists = selectFromDB('localhost', USER_NAME, 'twigrapher', 'utf8mb4', 'AllFromTwitterAPI', ['id', 'json_col', 'extracted'], "WHERE extracted = 0 AND request_type = 'getAllListsByScreenName'")
    req = formRequestArray(lists, 'getAllListsByScreenName', screen_name)
    insertToDB('localhost', USER_NAME, 'twigrapher', 'utf8mb4', 'lists', req[0], req[1])

    updateExtractedFlag('localhost', USER_NAME, 'twigrapher', 'utf8mb4', 'AllFromTwitterAPI', [['extracted']], [[1]], "WHERE extracted = 0  AND request_type = 'getAllListsByScreenName'")





# main -------------

getTweets('chromascore')
# getFavs('chromascore')
# getFriends('chromascore')
# getFollowers('chromascore')
# getLists('chromascore')

